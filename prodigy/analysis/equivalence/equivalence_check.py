from __future__ import annotations

import logging
from typing import Dict, List, Literal, Tuple

import sympy
from probably.pgcl import (Binop, BinopExpr, BoolLitExpr, IfInstr, NatLitExpr,
                           Program, SkipInstr, VarExpr, WhileInstr)

from prodigy.analysis.config import ForwardAnalysisConfig
from prodigy.analysis.instruction_handler import compute_discrete_distribution
from prodigy.distribution.distribution import Distribution, State
from prodigy.util.color import Style
from prodigy.util.logger import log_setup

logger = log_setup(__name__, logging.DEBUG)


def phi(program: Program, invariant: Program) -> Program:
    """
        The characteristic loop functional. It unrolls a loop exactly once.

        .. returns: A new program object equivaelnt to one loop unrolling of :param: program.
    """
    assert isinstance(
        program.instructions[0],
        WhileInstr), "Program can only be one big loop to analyze."
    logger.debug("Create modified invariant program.")
    new_instructions = program.instructions[0].body.copy()

    for instr in invariant.instructions:
        new_instructions.append(instr)

    guarded_instr = IfInstr(cond=program.instructions[0].cond,
                            true=new_instructions,
                            false=[SkipInstr()])

    return Program(declarations=invariant.declarations,
                   variables=invariant.variables,
                   constants=invariant.constants,
                   parameters=invariant.parameters,
                   instructions=[guarded_instr])


def generate_equivalence_test_distribution(
        program: Program,
        config: ForwardAnalysisConfig) -> Tuple[Distribution, Dict[str, str]]:
    """
        Generates a second-order PGF, dependent on the given variables in a program. This SOP can be used to check
        equivalences of two programs.

        .. returns: The SOP expression.
    """
    logger.debug("Generating test distribution.")
    dist = config.factory.one()
    so_vars: Dict[str, str] = {}  # second order variables
    for variable in program.variables:
        new_var = dist.get_fresh_variable()
        dist *= config.factory.from_expr(f"1/(1-{new_var}*{variable})",
                                         VarExpr(var=new_var),
                                         VarExpr(var=variable))
        so_vars[new_var] = variable
    return dist.set_variables(*program.variables.keys(),
                              *so_vars.keys()).set_parameters(), so_vars


def check_equivalence(
    program: Program, invariant: Program, config: ForwardAnalysisConfig
) -> Tuple[Literal[True], List[Dict[str, str]]] | Tuple[
        Literal[False], State] | Tuple[None, Distribution]:
    """
    This method uses the fact that we can sometimes determine program equivalence,
    by checking the equality of two parametrized infinite-state Distributions.

    If they are equivalent, also returns a list of constraints under which this holds
    (which may be empty if they are always equal). If not, also returns a counterexample.
    If the solution cannot be determined (returns `None`), also returns the difference of
    the second order distributions generated by the invariant and the once unrolled while
    loop of the program. If this difference can be made equal to 0, the programs are
    equivalent.
    .. param config: The configuration.
    .. param program: The While-Loop program
    .. param invariant: The loop-free invariant
    .. returns: Whether the invariant and the program are equivalent.
    """

    logger.debug("Checking equivalence.")
    # First we create the modified input program in order to fit the premise of Park's Lemma
    if config.show_intermediate_steps:
        print(
            f"{Style.YELLOW} Generate modified invariant program. {Style.RESET}"
        )
    modified_inv = phi(program, invariant)

    # Now we have to generate a infinite state parametrized distribution for every program variable.
    if config.show_intermediate_steps:
        print(
            f"{Style.YELLOW} Generate second order generating function. {Style.RESET}"
        )
    test_dist, new_vars = generate_equivalence_test_distribution(
        program, config)

    # Compute the resulting distributions for both programs
    logger.debug("Compute the modified invariant...")
    if config.show_intermediate_steps:
        print(
            f"\n{Style.YELLOW} Compute the result of the modified invariant. {Style.RESET}"
        )
    modified_inv_result = compute_discrete_distribution(
        modified_inv, test_dist, config)
    logger.debug("modified invariant result:\t%s", modified_inv_result)
    logger.debug("Compute the invariant...")
    if config.show_intermediate_steps:
        print(
            f"\n{Style.YELLOW} Compute the result of the invariant. {Style.RESET}"
        )
    inv_result = compute_discrete_distribution(invariant, test_dist, config)
    logger.debug("invariant result:\t%s", inv_result)
    # Compare them and check whether they are equal.
    logger.debug("Compare results")
    if config.show_intermediate_steps:
        print(
            f"\n{Style.YELLOW} Compare the results. {Style.RESET} \n {modified_inv_result}\n==\n{inv_result}"
        )
    if modified_inv_result == inv_result:
        logger.debug("Invariant validated.")
        empty: List[Dict[str, str]] = []  # Necessary to satisfy mypy
        return True, empty
    else:
        logger.debug("Invariant could not be validated.")
        diff = modified_inv_result - inv_result
        params = program.parameters.keys() | invariant.parameters.keys()

        def find_counterexample() -> State:
            """
            Under the assumption that the invariant and the program are not equivalent,
            finds an input state where they produce different results.
            """

            cond_doesnt_hold = test_dist - test_dist.filter(
                program.instructions[0].cond)
            result = compute_discrete_distribution(invariant, cond_doesnt_hold,
                                                   config)
            if result != cond_doesnt_hold:
                count_ex, _ = (result - cond_doesnt_hold).set_variables(
                    *new_vars.keys()).get_state()
            else:
                count_ex, _ = diff.set_variables(*new_vars.keys()).get_state()

            res = {}
            for var in count_ex:
                res[new_vars[var]] = count_ex[var]
            logger.debug("Found counterexample: %s", res)
            return State(res)

        if len(params & diff.get_symbols()) == 0:
            # There are no parameters, so the results can't be unified
            return False, find_counterexample()
        else:
            # First we let sympy try to find a solution
            solution = sympy.solve(sympy.S(str(diff)), *params, dict=True)
            unify = []
            for sol in solution:
                for _, val in sol.items():
                    if not {str(s) for s in val.free_symbols} <= params:
                        break
                else:
                    unify.append(sol)
            if len(unify) > 0:
                logger.debug(
                    "Found constraints under which the invariant can be validated: %s",
                    unify)
                return True, [{str(var): str(val)
                               for var, val in x.items()} for x in unify]

            # If we don't find a solution, try to prove that there is none by comparing coefficients
            logger.debug(
                "Could not find a solution, trying to prove that there is none"
            )
            if config.show_intermediate_steps:
                print(
                    f'{Style.YELLOW}Could not find a solution, trying to prove that there is none...{Style.RESET}'
                )
            inv_result_params = inv_result.set_variables(*new_vars.keys())
            modified_inv_result_params = modified_inv_result.set_variables(
                *new_vars.keys())
            count = 0
            # TODO add a break after some number of loop iterations (else we may not terminate)
            for _, state in inv_result_params:
                cond = BoolLitExpr(True)
                for var, val in state.items():
                    cond = BinopExpr(lhs=BinopExpr(lhs=VarExpr(var),
                                                   operator=Binop.EQ,
                                                   rhs=NatLitExpr(val)),
                                     operator=Binop.AND,
                                     rhs=cond)
                mass_diff = sympy.S(
                    str(
                        modified_inv_result_params.filter(
                            cond).get_probability_mass())
                ) - sympy.S(
                    str(inv_result_params.filter(cond).get_probability_mass()))
                syms = {str(s) for s in mass_diff.free_symbols} & params
                if len(syms) > 0:
                    sol = []
                    for el in sympy.solve(mass_diff, *syms, dict=True):
                        for var, val in el.items():
                            if not {str(s)
                                    for s in val.free_symbols} <= params:
                                break
                        else:
                            sol.append(el)
                    if config.show_intermediate_steps:
                        count += 1
                        print(f'\rCompared {count} coefficients', end='')
                    if len(sol) == 0:
                        # If there are coefficients that cannot be unified, we found a counterexample
                        logger.debug(
                            "Found coefficients that cannot be unified: %s",
                            state.valuations)
                        if config.show_intermediate_steps:
                            print()
                        return False, find_counterexample()

            if config.show_intermediate_steps:
                print()
            # We couldn't prove that the results can be unified, but we also failed to find a counterexample
            return None, diff
